<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Image-processing on Unqualified Success</title>
    <link>https://karledwards.github.io/tags/image-processing/</link>
    <description>Recent content in Image-processing on Unqualified Success</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 14 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://karledwards.github.io/tags/image-processing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Images Like This</title>
      <link>https://karledwards.github.io/project/images-like-this/</link>
      <pubDate>Sun, 14 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/project/images-like-this/</guid>
      <description>The General Idea Given a set of images, find the ones that are most similar to a set of examples.
More Specifically Given a dataset, comprising image features extracted using a pre-trained model, and given also the row identifiers for a subset of the data, representing the kind of images to find, create a TRAINING set of the specified rows and a TEST set of all remaining rows, then train a binary SVM classifier to identify images in the TEST set, which are similar to those in the TRAINING set.</description>
    </item>
    
    <item>
      <title>Photogrammetric Potsherd Profile</title>
      <link>https://karledwards.github.io/project/photogrammetric-potsherd/</link>
      <pubDate>Tue, 31 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/project/photogrammetric-potsherd/</guid>
      <description>The General Idea Make photogrammetry readily accessible to archaeologists through open source computational archaeology.
More Specifically This project describes in some detail the steps to photograph a potsherd and generate a mathematical model from the resulting images, and, in much less detail, suggests how to automatically measure the object represented by the model. The R source code is available on github and an R package will be available soon. A number of simplifying assumptions accelerated this initial draft.</description>
    </item>
    
  </channel>
</rss>m>
      <title>Ultimate Captioning Part 3</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-scorecard/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-scorecard/</guid>
      <description>Scorecard What are the individual tasks involved in solving the whole problem, and how effective are various approaches to these tasks?
General Tasks    Id Task Approach Details     G1 Extract images from video Shell script to drive command-line VLC See Practical VLC   G2 Partition a set of labeled images Shell script to randomly select training and testing examples, based on a list of files and class labels See Partitioning Data    Image Classification Since the field, the disc, and the players are the key ingredients for a game, tools focused on detecting these items would be a reasonable place to start.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 2</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-approaches/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-approaches/</guid>
      <description>The sport of ultimate resembles soccer in some ways. For example, both sports revolve around groups of similarly-clad individuals running around a mostly green environment, focused on a small, fast-moving object. Efforts to understand Soccer present many promising ideas for understanding ultimate.
The single image at the top of this post illustrates an action by itself: A player leaps into the air, attempting to catch the disc. Many times, motion from subsequent frames will be required in order to discern the action.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 1</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-problem-rmd/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-problem-rmd/</guid>
      <description>How can we choose the best 150 two-second plays from 10 or more hours of raw video? Preparing a highlights video from raw footage is an intensely time-consuming endeavor. This post begins with a brief introduction to the sport of Ultimate, followed by an overview of the temporal structure of a game and temporal structure of scoring a single point. The data inventory describes various sources of information about the game and the post concludes with a glossary and a short list of simplifying assumptions.</description>
    </item>
    
  </channel>
</rss>