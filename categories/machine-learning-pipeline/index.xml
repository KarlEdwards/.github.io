<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning Pipeline on Unqualified Success</title>
    <link>https://karledwards.github.io/categories/machine-learning-pipeline/</link>
    <description>Recent content in Machine Learning Pipeline on Unqualified Success</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Thu, 26 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://karledwards.github.io/categories/machine-learning-pipeline/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Add a Task to Add Some Tasks</title>
      <link>https://karledwards.github.io/post/a-simple-scheduler/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/a-simple-scheduler/</guid>
      <description>Now let’s use Schedule_Reference_Class.R in a real-world situation.
Create a schedule with a single task – to apply a recipe to all the video files in the in-box.
 Perform the task and view the resulting schedule.
 Perform the steps of the recipe, following along as each task finishes.
  Create a Schedule with a task to apply a recipe to a bunch of files.
s &amp;lt;- Schedule( fun=&amp;#39;build_recipes&amp;#39; , args=&amp;quot;list( applied_recipes , the_schedule = s )&amp;quot; ) Show the schedule:</description>
    </item>
    
    <item>
      <title>An ML Pipeline in R</title>
      <link>https://karledwards.github.io/post/an-ml-pipeline-in-r/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/an-ml-pipeline-in-r/</guid>
      <description>At the beginning of a new machine learning project, it&#39;s a good idea to create a baseline model that functions end-to-end, even if the performance is not very good. Soon enough, you will think of ideas for better models, and want to try them, evaluate their performance, and maybe keep them for future use in a production environment. Over the lifetime of a project, data presented to the pipeline inlet are processed according to a particular recipe, which generates some useful output.</description>
    </item>
    
  </channel>
</rss>