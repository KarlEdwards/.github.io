<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.37" />
  <meta name="author" content="Karl Edwards">

  
  
  
  
    
      
    
  
  <meta name="description" content="The task is to classify images: which ones depict a disc, and which ones do not? Using a manually-labeled collection of over 3,000 images, partition the data into training and testing sets, extract features using Histograms of Oriented Gradients (HoGs), train a linear support vector machine on the training set, and classify the images from the testing set. Examine the effect on classifier performance resulting from varying the proportion of examples used for training vs.">

  
  <link rel="alternate" hreflang="en-us" href="/post/ultimate-captioning-detector/">

  


  

  
  
  <meta name="theme-color" content="hsl(30, 90%, 68%)">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/zenburn.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Unqualified Success">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Unqualified Success">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/ultimate-captioning-detector/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Unqualified Success">
  <meta property="og:url" content="/post/ultimate-captioning-detector/">
  <meta property="og:title" content="Ultimate Captioning Disc Detector | Unqualified Success">
  <meta property="og:description" content="The task is to classify images: which ones depict a disc, and which ones do not? Using a manually-labeled collection of over 3,000 images, partition the data into training and testing sets, extract features using Histograms of Oriented Gradients (HoGs), train a linear support vector machine on the training set, and classify the images from the testing set. Examine the effect on classifier performance resulting from varying the proportion of examples used for training vs.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-04-05T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-04-05T00:00:00&#43;00:00">
  

  

  <title>Ultimate Captioning Disc Detector | Unqualified Success</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" class="dark">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Unqualified Success</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Ultimate Captioning Disc Detector</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2018-04-05 00:00:00 &#43;0000 UTC" itemprop="datePublished dateModified">
      2018-04-05
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Karl Edwards">
  </span>

  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/projects">projects</a
    >, 
    
    <a href="/categories/posts">posts</a
    >
    
  </span>
  
  

  
  

  

</div>


    <div class="article-style" itemprop="articleBody">
      <p>The task is to classify images: which ones depict a disc, and which ones do not? Using a manually-labeled collection of over 3,000 images, partition the data into training and testing sets, extract features using Histograms of Oriented Gradients (HoGs), train a linear support vector machine on the training set, and classify the images from the testing set. Examine the effect on classifier performance resulting from varying the proportion of examples used for training vs. testing and the number of cells used for extracting HoGs from each image.</p>
<hr />
<div id="data" class="section level2">
<h2>Data</h2>
<div id="data-source" class="section level3">
<h3>Data Source</h3>
<p>3471 images, excerpted from 2015bsVriot.mp4, roughly 1 frame per second for about 1 hour.</p>
</div>
<div id="data-preparation" class="section level3">
<h3>1. Data Preparation</h3>
<p>A. Manually label a list of the images as a plain, unformatted text file, where each row of the file begins with the bare file name, i.e., <em>frame_12345.png</em>, optionally followed by descriptive text, as shown here. Note that multiple key words may appear, in any order, on a line.</p>
<blockquote>
<ul>
<li>frame_102391.png</li>
<li>frame_102361.png disc</li>
<li>frame_102451.png</li>
<li>frame_102481.png two-players</li>
<li>frame_102511.png</li>
<li>rame_102781.png pull</li>
<li>frame_102811.png</li>
<li>frame_104101.png</li>
<li>frame_10411.png disc</li>
<li>frame_19921.png disc</li>
<li>frame_19951.png player-on-ground disc</li>
<li>frame_20461.png between-points</li>
<li>frame_20041.png</li>
</ul>
</blockquote>
<p>B. Partition the labeled data into multiple training and testing sets in order to see what effect the number of training rows has on the effectiveness of the detector.</p>
<p>See <a href="https://github.com/Video-Captioning/partition_datasets" class="uri">https://github.com/Video-Captioning/partition_datasets</a></p>
<pre class="bash"><code># Generate three data sets, using a progressively higher
# percentage of examples for training:
cd `PROJECTPATH`
for fraction in 0.40 0.50 0.60
  do
    ./partition_data_two_class.sh `KEYWORD` `CLASS_LABELS` $fraction
  done
</code></pre>
</div>
<div id="make-histograms-of-oriented-gradients-hogs" class="section level3">
<h3>2. Make Histograms of Oriented Gradients (HoGs)</h3>
<p>See <a href="https://github.com/Video-Captioning/HoG" class="uri">https://github.com/Video-Captioning/HoG</a></p>
<p>The number of bins remains constant at 9 for the following, while the number of cells varies from 4 to 9:</p>
<pre class="bash"><code>for fraction in 40 50 60; do
  cd `PROJECTPATH``KEYWORD`$fraction
  for bins in 4 5 6 7 8 9; do
    ../hog.sh ../data/2_images/ $bins 9
  done
done</code></pre>
</div>
<div id="classify-images" class="section level3">
<h3>3. Classify Images</h3>
<p>To classify the images in the test set, we first train the model using the e1071 package – an R package with an interface to a C++ implementation of support vector machines. By combining two functions from this package, <em>svm</em> and <em>tune</em>, we can explore a range of costs and choose the one that gives the best performance. The basic arrangement follows:</p>
<pre class="r"><code># Optimize cost parameter, C,
# by training an SVM classifier using each of the
# C-values given in input, values_of_C_to_try
optimize_cost &lt;- function( values_of_C_to_try, test_data ){
  cat( sprintf( &#39;Finding optimal cost...\n&#39; ))
  e1071::tune(
      e1071::svm
    , y~.
    , data   = test_data
    , kernel = &#39;linear&#39;
    , ranges = values_of_C_to_try
  )
}</code></pre>
<p>This code is combined with additional supporting functions in <a href="https://github.com/Video-Captioning/SVM-two-class">SVM_functions.R</a>.</p>
<p>All the pieces to classify HoGs for a single configuration (training fraction, cells, bins) are in <a href="https://github.com/Video-Captioning/SVM-two-class">SVM_classify_one_set.R</a>, which performs the following:</p>
<ul>
<li>Get the training and testing data</li>
<li>Optimize cost parameter, <em>C</em>, using the training set</li>
<li>Make predictions using best model on the testing set</li>
<li>Compute a confusion matrix, calculate F1-scores and area-under-the ROC curve.</li>
</ul>
<p>To process the entire collection of configurations, we can call SVM_classify_one_set for each item of a list with the following R code:</p>
<pre class="r"><code># ----- Load the functions to use for this analysis -----
require( purrr )
libraries &lt;- list( &#39;SVM_functions&#39;, &#39;SVM_classify_one_set&#39; )
LIBRARY_PATH &lt;- &#39;/path/to/repository&#39;
DATA_PATH    &lt;- &#39;/path/to/data/&#39;
libraries %&gt;%
  map_chr( .f= ~paste0( LIBRARY_PATH, .x, &#39;.R&#39; )) %&gt;%
  walk( source )

# ----- Describe which data sets to process -------------
BATCHES &lt;- list(
  
    &#39;disc40/cells4_bins9/&#39;
  , &#39;disc40/cells5_bins9/&#39;
  , &#39;disc40/cells6_bins9/&#39;
  , &#39;disc40/cells7_bins9/&#39;
  , &#39;disc40/cells8_bins9/&#39;
  , &#39;disc40/cells9_bins9/&#39;
  
  , &#39;disc50/cells4_bins9/&#39;
  , &#39;disc50/cells5_bins9/&#39;
  , &#39;disc50/cells6_bins9/&#39;
  , &#39;disc50/cells7_bins9/&#39;
  , &#39;disc50/cells8_bins9/&#39;
  , &#39;disc50/cells9_bins9/&#39;
  
  , &#39;disc60/cells4_bins9/&#39;
  , &#39;disc60/cells5_bins9/&#39;
  , &#39;disc60/cells6_bins9/&#39;
  , &#39;disc60/cells7_bins9/&#39;
  , &#39;disc60/cells8_bins9/&#39;
  , &#39;disc60/cells9_bins9/&#39;
)

# ----- Process the data sets ----------------------------
map2( DATA_PATH, BATCHES, ~SVM_classify_one_set( .x, .y ))</code></pre>
</div>
<div id="collect-and-summarize-results" class="section level3">
<h3>4. Collect and Summarize Results</h3>
<p><a href="https://github.com/Video-Captioning/SVM-two-class">Recursive_score_collection.sh</a> searches for all the <em>keyword</em> <em>training_fraction</em> subdirectories and captures the previously-recorded scores at each location.</p>
<p>Plot the results with <a href="https://github.com/Video-Captioning/SVM-two-class/SVM_evaluation.R">SVM_evaluation.R</a></p>
<pre class="r"><code># --- Load libraries ---
require( ggplot2 )</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre class="r"><code># --- Get the data ---
SCORES &lt;- &#39;../../data/scores.txt&#39;
#dir( path = &#39;../../data/&#39; )
x &lt;- read.csv( file = SCORES, header=TRUE,sep=&#39;|&#39; )</code></pre>
<p><img src="/post/Part4_files/figure-html/unnamed-chunk-6-1.png" width="672" /> Using 4 cells was quick (about two minutes), but not very accurate, measured by area under the receiver operator characteristic curve.</p>
<p>Using 10 cells, feature extraction took 20 minutes or more. Using 50% of the images for training performed better than using 40% or 60%, and was quicker than using 40%. <img src="/post/Part4_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Feature extraction rate (rows per second) is <em>very</em> slow for 10 cells, moderate for 7 to 9 cells, and considerably faster for 4 cells. <img src="/post/Part4_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>AUC_by_N_cells_points <img src="/post/Part4_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>See <a href="https://www.mathworks.com/help/vision/ref/extracthogfeatures.html?requestedDomain%20=%20true">MathWorks extractHOGFeatures</a></p>
<ul>
<li>To capture large-scale spatial information, increase the cell size. When you increase the cell size, you may lose small-scale detail.</li>
<li>To encode finer orientation details, increase the number of bins. Increasing this value increases the size of the feature vector, which requires more time to process.</li>
</ul>
</div>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/image-processing">image processing</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/ultimate-captioning-scorecard/">Ultimate Captioning Part 3</a></li>
        
        <li><a href="/post/ultimate-captioning-approaches/">Ultimate Captioning Part 2</a></li>
        
        <li><a href="/post/ultimate-captioning-problem-rmd/">Ultimate Captioning Part 1</a></li>
        
      </ul>
    </div>
    

    
    <div class="article-widget">
      <div class="post-nav">
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/post/ultimate-captioning-list-of-posts/" rel="next">Ultimate Captioning Posts</a>
  </div>
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/post/ultimate-captioning-scorecard/" rel="prev">Ultimate Captioning Part 3</a>
  </div>
  
</div>

    </div>
    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/R.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

