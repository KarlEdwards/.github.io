<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.37" />
  <meta name="author" content="Karl Edwards">

  
  
  
  
    
      
    
  
  <meta name="description" content="The task: Create a baseline disc classifier. The basic idea is to classify the images into two buckets: those that depict a disc (positive examples), and those that do not (negative examples).
We will need:  Data Features Classifier  The Classifier will separate the data into positive and negative bins, based on Features extracted from the (labeled) Data.
 Data \(\implies\) \(\fbox{ Extractor }\) \(\implies\) Features
Features \(\implies\) \(\fbox{ Classifier }\) \(\implies\) Predictions">

  
  <link rel="alternate" hreflang="en-us" href="https://karledwards.github.io/post/ultimate-captioning-detector/">

  


  

  
  
  <meta name="theme-color" content="hsl(30, 90%, 68%)">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/zenburn.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://karledwards.github.io/index.xml" type="application/rss+xml" title="Unqualified Success">
  <link rel="feed" href="https://karledwards.github.io/index.xml" type="application/rss+xml" title="Unqualified Success">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://karledwards.github.io/post/ultimate-captioning-detector/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Unqualified Success">
  <meta property="og:url" content="https://karledwards.github.io/post/ultimate-captioning-detector/">
  <meta property="og:title" content="Ultimate Captioning Part 4 | Unqualified Success">
  <meta property="og:description" content="The task: Create a baseline disc classifier. The basic idea is to classify the images into two buckets: those that depict a disc (positive examples), and those that do not (negative examples).
We will need:  Data Features Classifier  The Classifier will separate the data into positive and negative bins, based on Features extracted from the (labeled) Data.
 Data \(\implies\) \(\fbox{ Extractor }\) \(\implies\) Features
Features \(\implies\) \(\fbox{ Classifier }\) \(\implies\) Predictions">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-04-26T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-04-26T00:00:00&#43;00:00">
  

  

  <title>Ultimate Captioning Part 4 | Unqualified Success</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" class="dark">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Unqualified Success</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Ultimate Captioning Part 4</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2018-04-26 00:00:00 &#43;0000 UTC" itemprop="datePublished dateModified">
      2018-04-26
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Karl Edwards">
  </span>

  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/projects">projects</a
    >, 
    
    <a href="/categories/posts">posts</a
    >
    
  </span>
  
  

  
  

  

</div>


    <div class="article-style" itemprop="articleBody">
      <div id="the-task-create-a-baseline-disc-classifier." class="section level4">
<h4>The task: Create a baseline disc classifier.</h4>
<p>The basic idea is to classify the images into two buckets: those that depict a disc (positive examples), and those that do not (negative examples).</p>
<div id="we-will-need" class="section level5">
<h5>We will need:</h5>
<ul>
<li>Data</li>
<li>Features</li>
<li>Classifier</li>
</ul>
<p>The <em>Classifier</em> will separate the data into positive and negative bins, based on <em>Features</em> extracted from the (labeled) <em>Data</em>.</p>
<blockquote>
<p>Data <span class="math inline">\(\implies\)</span> <span class="math inline">\(\fbox{ Extractor }\)</span> <span class="math inline">\(\implies\)</span> Features</p>
<p>Features <span class="math inline">\(\implies\)</span> <span class="math inline">\(\fbox{ Classifier }\)</span> <span class="math inline">\(\implies\)</span> Predictions</p>
</blockquote>
</div>
<div id="which-classifier" class="section level5">
<h5>Which classifier?</h5>
<p>Scikit-learn.org has a handy flowchart, <a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">Choosing the Right Estimator</a>, which suggests starting with a linear support vector classifier when there are fewer than 100,000 examples of labeled data.</p>
</div>
<div id="which-feature-extractor" class="section level5">
<h5>Which Feature Extractor?</h5>
<p>Let’s begin with a feature extractor known for its object-detection performance: Histograms of Oriented Gradients ( HoGs, for short ) described <a href="https://pdfs.semanticscholar.org/presentation/342b/c8b55d46f822e1574e4c6fccaa0b8bfa5d3b.pdf">here</a>.</p>
</div>
<div id="refinements" class="section level5">
<h5>Refinements</h5>
<p>Later, when we want a <em>better</em> classifer, <a href="https://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/">this</a> article will be useful.</p>
</div>
<div id="the-major-steps" class="section level5">
<h5>The major steps</h5>
<ol style="list-style-type: decimal">
<li>Label the training and testing images</li>
<li>Extract features using HoGs</li>
<li>Classify Images and Evaluate Performance</li>
<li>Summarize the results</li>
</ol>
<hr />
</div>
</div>
<div id="label-the-training-and-testing-images" class="section level2">
<h2>1. Label the training and testing images</h2>
<div id="a.-data-source" class="section level3">
<h3>A. Data Source</h3>
<p>Data for this post comprise 3471 images, excerpted from <a href="https://www.youtube.com/watch?v=ULzQS2rv34s">Women’s Final from the 2015 National Championships</a>, in which Boston Brute Squad takes on Seattle Riot in Frisco, Texas. The images are extracted at a rate of roughly 1 frame per second for about 1 hour.</p>
<pre class="bash"><code># -----------------------------------------------
# Save video from the web using VLC:
# -----------------------------------------------

vlc -v -I rc --no-sout-audio --sout=&#39;#transcode{ vcodec=h264, vb=800, scale=1 }:std{ access=file,
mux=ts, dst=/path/to/resulting/video.mp4 }&#39; https://www.youtube.com/watch?v=ULzQS2rv34s/ vlc://quit

# -----------------------------------------------
# Extract an excerpt of the video as a series of images:
# -----------------------------------------------

vlc $video_file  --start-time $start_time_seconds --run-time $run_time_seconds --sout \&#39;#transcode{ vfilter = scene{ ratio = $FRAME_RATIO, prefix = $FILE_PREFIX, path = $output_path, out=dummy }, vcodec = theo, vb = 2000,scale = 1.0, acodec = none }:standard{ access = file, mux = ogg, dst = \&quot;dummy.ogg\&quot; }\&#39; vlc://quit

# See https://github.com/Video-Captioning/Practical-VLC</code></pre>
</div>
<div id="b.-data-preparation" class="section level3">
<h3>B. Data Preparation</h3>
<div id="manually" class="section level4">
<h4><em>Manually</em>:</h4>
<ul>
<li>Create a list of images in a plain, unformatted text file, with one file name on each line</li>
<li>Include descriptive text after the file name</li>
<li>Multiple keywords may appear in any order on a line</li>
</ul>
<p>Example:</p>
<table>
<thead>
<tr class="header">
<th>File  Name               [ optional descriptive text ]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>frame_20041.png</td>
</tr>
<tr class="even">
<td>frame_02911.png</td>
</tr>
<tr class="odd">
<td>frame_02941.png disc</td>
</tr>
<tr class="even">
<td>frame_02971.png field players running</td>
</tr>
<tr class="odd">
<td>frame_03001.png field players running</td>
</tr>
<tr class="even">
<td>frame_03031.png blurry</td>
</tr>
<tr class="odd">
<td>frame_03061.png field players running</td>
</tr>
<tr class="even">
<td>frame_03091.png field players running</td>
</tr>
<tr class="odd">
<td>frame_03121.png field players looking_up</td>
</tr>
<tr class="even">
<td>frame_03151.png disc field players running</td>
</tr>
<tr class="odd">
<td>frame_03181.png field players</td>
</tr>
<tr class="even">
<td>frame_03211.png disc blurry</td>
</tr>
<tr class="odd">
<td>frame_03241.png blurry</td>
</tr>
<tr class="even">
<td>frame_03271.png disc_flying</td>
</tr>
<tr class="odd">
<td>frame_03301.png disc_flying field players running</td>
</tr>
<tr class="even">
<td>frame_03331.png field players jumping</td>
</tr>
<tr class="odd">
<td>frame_03361.png field players landing</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="extract-features-using-hogs" class="section level2">
<h2>2. Extract features using HoGs</h2>
<p>Make training and testing datasets for the keyword, <em>disc</em>, selecting training and testing examples at random from the labeled data:</p>
<pre class="bash"><code># 80% of images for training; 20% for testing
#
# partition the data ---+    +--- training fraction
#                       |    |       +--- keyword
#      the script       |    |       |          +--- class label file
#          |            |    |       |          |
# ____________________ __ _______ _______ ___________________
./object_detector.sh -p -f 0.80 -k disc -l labeled_3471.txt</code></pre>
<p>This will produce a subdirectory named <em>disc80</em> and four files containing the names of image files for both positive and negative examples.</p>
<pre><code>|
+--disc80
|       +--testing_neg.txt
|       +--testing_pos.txt
|       +--training_neg.txt
|       +--training_pos.txt
|</code></pre>
<p>Now, let’s extract HoG features, using 8 cells and 15 bins.</p>
<pre class="bash"><code># Initiate feature extraction
#
# number of cells (windows)---+     +--- number of bins
#    eXtract features ---+    |     |       +--- keyword
#      the script        |    |     |       |        +--- training fraction
#          |             |    |     |       |        |
# ____________________  __  ____  _____  _______  _______
./object_detector.sh  -x  -w 8  -b 15  -k disc  -f 0.80</code></pre>
<p>Two parameters, the number of <em>Cells</em> and the number of <em>Bins</em>, affect the size, shape, and orientation of objects that can be detected. The dimensionality of the resulting feature set is proportional to the number of bins and to the square of the number of cells, so, for both processing time and accuracy of predictions, it is important to get these parameters at least somewhat optimized.</p>
<p>The experiments in this post utilize OpenImageR, SimpleCV, and OpenCV – three open-source packages, which are described briefly, below:</p>
<blockquote>
<p>OpenImageR <span class="math inline">\(\implies\)</span> SimpleCV <span class="math inline">\(\implies\)</span> OpenCV</p>
<p><a href="https://www.rdocumentation.org/packages/OpenImageR/versions/1.0.8">OpenImageR</a> is an Image Processing Toolkit that takes advantage of ‘RcppArmadillo’ to speed up computationally intensive functions. The histogram of oriented gradients descriptor is a modification of the ‘findHOGFeatures’ function of the ‘SimpleCV’ computer vision platform.</p>
<p><a href="http://simplecv.org">SimpleCV</a> is an open source framework for building computer vision applications that uses libraries such as OpenCV.</p>
<p><a href="https://opencv.org">OpenCV</a> is a library of programming functions mainly aimed at real-time computer vision.</p>
</blockquote>
</div>
<div id="classify-images-and-evaluate-performance" class="section level2">
<h2>3. Classify Images and Evaluate Performance</h2>
<pre class="bash"><code># Initiate image classification
#
# number of cells (windows)---+     +--- number of bins
#            classify ---+    |     |       +--- keyword
#      the script        |    |     |       |        +--- training fraction
#          |             |    |     |       |        |
# ____________________  __  ____  _____  _______  _______
./object_detector.sh  -c  -w 8  -b 15  -k disc  -f 0.80

# Feature extraction and image classification can be requested together:
./object_detector.sh  -x -c  -w 8  -b 15  -k disc  -f 0.80

for bins in 10 11 12 13 14 15; do
  ./object_detector.sh  -x -c  -w 6  -b $bins  -k disc  -f 0.80
done

for cells in 3 4 5 6 7 8 9 10 11 12 13 14 15; do
  ./object_detector.sh  -x -c  -w $cells  -b 17  -k disc  -f 0.80
done</code></pre>
</div>
<div id="summarize-the-results" class="section level2">
<h2>4. Summarize the results</h2>
<pre class="bash"><code>./library/Recursive-score-collection.sh disc &gt; scores.txt
./show_scores.R</code></pre>
<div class="figure">
<img src="/img/uc4-fig1.png" alt="Overall performance by cells and bins." />
<p class="caption">Overall performance by cells and bins.</p>
</div>
<div id="which-images-are-mis-classified" class="section level3">
<h3>Which images are mis-classified?</h3>
</div>
<div id="why-are-images-mis-classified" class="section level3">
<h3>Why are images mis-classified?</h3>
<div class="figure">
<img src="/img/uc4-fig2.png" alt="False Positives by cells and bins." />
<p class="caption">False Positives by cells and bins.</p>
</div>
<div class="figure">
<img src="/img/uc4-fig3.png" alt="True Negatives by cells and bins." />
<p class="caption">True Negatives by cells and bins.</p>
</div>
<hr />
</div>
</div>
<div id="github" class="section level2">
<h2>GitHub</h2>
<p>For details of the code behind the examples used in this post, please see the following repositories:</p>
<ul>
<li><p><a href="https://github.com/Video-Captioning/HoG/blob/master/object_detector.sh">Object Detection</a></p></li>
<li><p><a href="https://github.com/Video-Captioning/partition_datasets">Partitioning</a></p></li>
<li><p><a href="https://github.com/Video-Captioning/SVM-two-class">Classification</a></p></li>
</ul>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/image-processing">image processing</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/ultimate-captioning-scorecard/">Ultimate Captioning Part 3</a></li>
        
        <li><a href="/post/ultimate-captioning-approaches/">Ultimate Captioning Part 2</a></li>
        
        <li><a href="/post/ultimate-captioning-problem-rmd/">Ultimate Captioning Part 1</a></li>
        
      </ul>
    </div>
    

    
    <div class="article-widget">
      <div class="post-nav">
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="https://karledwards.github.io/post/ultimate-captioning-scorecard/" rel="prev">Ultimate Captioning Part 3</a>
  </div>
  
</div>

    </div>
    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/R.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

