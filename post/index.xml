<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Unqualified Success</title>
    <link>https://karledwards.github.io/post/</link>
    <description>Recent content in Posts on Unqualified Success</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Thu, 26 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://karledwards.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Add a Task to Add Some Tasks</title>
      <link>https://karledwards.github.io/post/a-simple-scheduler/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/a-simple-scheduler/</guid>
      <description>Now let’s use Schedule_Reference_Class.R in a real-world situation. First, we create a schedule with a single task – to apply a recipe to all the video files in the in-box. Second, we perform the task and view the resulting schedule. Then we perform the steps of the recipe, following along as each task finishes.
Create a Schedule with a task to apply a recipe to a bunch of files.
s &amp;lt;- Schedule( fun=&amp;#39;build_recipes&amp;#39;, args=&amp;quot;list( applied_recipes, the_schedule = s )&amp;quot; )` | Error: &amp;lt;text&amp;gt;:1:87: unexpected INCOMPLETE_STRING | 1: s &amp;lt;- Schedule( fun=&amp;#39;build_recipes&amp;#39;, args=&amp;quot;list( applied_recipes, the_schedule = s )&amp;quot; )` | ^ Show the schedule:</description>
    </item>
    
    <item>
      <title>An ML Pipeline in R</title>
      <link>https://karledwards.github.io/post/an-ml-pipeline-in-r/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/an-ml-pipeline-in-r/</guid>
      <description>At the beginning of a new machine learning project, it&#39;s a good idea to create a baseline model that functions end-to-end, even if the performance is not very good. Soon enough, you will think of ideas for better models, and want to try them, evaluate their performance, and maybe keep them for future use in a production environment. Over the lifetime of a project, data presented to the pipeline inlet are processed according to a particular recipe, which generates some useful output.</description>
    </item>
    
    <item>
      <title>Fixed Camera Surveillance</title>
      <link>https://karledwards.github.io/post/fixed-camera-surveillance/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/fixed-camera-surveillance/</guid>
      <description>Abstract Fixed-camera surveillance has many practical applications, including, for example: inventory protection, vehicle tolling, robot localization, personnel authentication, and construction site monitoring. Each situation has its own ideosyncracies, however, a common pre-processing task is background subtraction. Although lighting conditions may vary, and smoke, fog, or mist might obscure the view, a significant portion of the picture does not change from one frame to the next, or even from one minute to the next.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 4</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-detector/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-detector/</guid>
      <description>The task: Create a baseline disc classifier. The basic idea is to classify the images into two buckets: those that depict a disc (positive examples), and those that do not (negative examples).
We will need:  Data Features Classifier  The Classifier will separate the data into positive and negative bins, based on Features extracted from the (labeled) Data.
 Data \(\implies\) \(\fbox{ Extractor }\) \(\implies\) Features
Features \(\implies\) \(\fbox{ Classifier }\) \(\implies\) Predictions</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 3</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-scorecard/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-scorecard/</guid>
      <description>Scorecard What are the individual tasks involved in solving the whole problem, and how effective are various approaches to these tasks?
General Tasks    Id Task Approach Details     G1 Extract images from video Shell script to drive command-line VLC See Practical VLC   G2 Partition a set of labeled images Shell script to randomly select training and testing examples, based on a list of files and class labels See Partitioning Data    Image Classification Since the field, the disc, and the players are the key ingredients for a game, tools focused on detecting these items would be a reasonable place to start.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 2</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-approaches/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-approaches/</guid>
      <description>The sport of ultimate resembles soccer in some ways. For example, both sports revolve around groups of similarly-clad individuals running around a mostly green environment, focused on a small, fast-moving object. Efforts to understand Soccer present many promising ideas for understanding ultimate.
The single image at the top of this post illustrates an action by itself: A player leaps into the air, attempting to catch the disc. Many times, motion from subsequent frames will be required in order to discern the action.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 1</title>
      <link>https://karledwards.github.io/post/ultimate-captioning-problem-rmd/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/ultimate-captioning-problem-rmd/</guid>
      <description>How can we choose the best 150 two-second plays from 10 or more hours of raw video? Preparing a highlights video from raw footage is an intensely time-consuming endeavor. This post begins with a brief introduction to the sport of Ultimate, followed by an overview of the temporal structure of a game and temporal structure of scoring a single point. The data inventory describes various sources of information about the game and the post concludes with a glossary and a short list of simplifying assumptions.</description>
    </item>
    
    <item>
      <title>About the Blog...</title>
      <link>https://karledwards.github.io/post/about-the-blog-rmd/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karledwards.github.io/post/about-the-blog-rmd/</guid>
      <description>Getting Started I began by trying to follow the instructions from these resources:
 Blogging with R Markdown, by Kevin Wong http://kevinfw.com/post/blogging-with-r-markdown/ Building a Blog with Blogdown and GitHub, by Tyler Clavelle https://tclavelle.github.io/blog/blogdown_github/ Announcing Blogdown, by Yihui Xie https://blog.rstudio.com/2017/09/11/announcing-blogdown/, along with https://github.com/rstudio/blogdown Blogging with Rmarkdown, knitr, and Jekyll, by Brendan Rocks, https://www.r-bloggers.com/blogging-with-rmarkdown-knitr-and-jekyll/ Happy Git and GitHub for the useR, by Jennifer Bryan, https://speakerdeck.com/jennybc/happy-git-and-github-for-the-user  After many false starts and nearly giving up, things finally started falling into place.</description>
    </item>
    
    <item>
      <title>R Example</title>
      <link>https://karledwards.github.io/post/2015-07-23-r-rmarkdown/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      
      <guid>https://karledwards.github.io/post/2015-07-23-r-rmarkdown/</guid>
      <description>R Markdown  </description>
    </item>
    
  </channel>
</rss>