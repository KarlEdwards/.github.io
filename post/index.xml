<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Unqualified Success</title>
    <link>/post/</link>
    <description>Recent content in Posts on Unqualified Success</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sat, 21 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Ultimate Captioning Posts</title>
      <link>/post/ultimate-captioning-list-of-posts/</link>
      <pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ultimate-captioning-list-of-posts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ultimate Captioning Disc Detector</title>
      <link>/post/ultimate-captioning-detector/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ultimate-captioning-detector/</guid>
      <description>The task is to classify images: which ones depict a disc, and which ones do not? Using a manually-labeled collection of over 3,000 images, partition the data into training and testing sets, extract features using Histograms of Oriented Gradients (HoGs), train a linear support vector machine on the training set, and classify the images from the testing set. Examine the effect on classifier performance resulting from varying the proportion of examples used for training vs.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 3</title>
      <link>/post/ultimate-captioning-scorecard/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ultimate-captioning-scorecard/</guid>
      <description>Data used for this scorecard  3,471 images, excerpted from 2015bsVriot.mp4 at a rate of roughly 1 frame per second for about 1 hour  , partition the labeled data into two sets: Some portion of the data for training and the rest for testing. After partitioning the data, ...
Scorecard What are the individual tasks, and how effective are various approaches?
General    Id Task Approach Details     G1 Extract images from video Shell script to drive command-line VLC See https://github.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 2</title>
      <link>/post/ultimate-captioning-approaches/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ultimate-captioning-approaches/</guid>
      <description>The sport of ultimate resembles soccer in some ways. For example, both sports revolve around groups of similarly-clad individuals running around a mostly green environment, focused on a small, fast-moving object. Efforts to understand Soccer present many promising ideas for understanding ultimate.
The single image at the top of this post illustrates an action by itself: A player leaps into the air, attempting to catch the disc. Many times, motion from subsequent frames will be required in order to discern the action.</description>
    </item>
    
    <item>
      <title>Ultimate Captioning Part 1</title>
      <link>/post/ultimate-captioning-problem-rmd/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ultimate-captioning-problem-rmd/</guid>
      <description>How can we choose the best 150 two-second plays from 10 or more hours of raw video? Preparing a highlights video from raw footage is an intensely time-consuming endeavor. This post begins with a brief introduction to the sport of Ultimate, followed by an overview of the temporal structure of a game and temporal structure of scoring a single point. The data inventory describes various sources of information about the game and the post concludes with a glossary and a short list of simplifying assumptions.</description>
    </item>
    
    <item>
      <title>About the Blog...</title>
      <link>/post/about-the-blog-rmd/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/about-the-blog-rmd/</guid>
      <description>Getting Started I began by trying to follow the instructions from these resources:
 Blogging with R Markdown, by Kevin Wong http://kevinfw.com/post/blogging-with-r-markdown/ Building a Blog with Blogdown and GitHub, by Tyler Clavelle https://tclavelle.github.io/blog/blogdown_github/ Announcing Blogdown, by Yihui Xie https://blog.rstudio.com/2017/09/11/announcing-blogdown/, along with https://github.com/rstudio/blogdown Blogging with Rmarkdown, knitr, and Jekyll, by Brendan Rocks, https://www.r-bloggers.com/blogging-with-rmarkdown-knitr-and-jekyll/ Happy Git and GitHub for the useR, by Jennifer Bryan, https://speakerdeck.com/jennybc/happy-git-and-github-for-the-user  After many false starts and nearly giving up, things finally started falling into place.</description>
    </item>
    
    <item>
      <title>R Example</title>
      <link>/post/2015-07-23-r-rmarkdown/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      
      <guid>/post/2015-07-23-r-rmarkdown/</guid>
      <description>R Markdown  </description>
    </item>
    
  </channel>
</rss>